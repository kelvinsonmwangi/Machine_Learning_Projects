---
title: "Credit Risk Modelling"
output: github_document
---

#### Loading the data
Data can be found [Here](https://raw.githubusercontent.com/obaidpervaizgill/CreditRiskModelling/master/credit.csv). We will exclude the `phone` variable. We will also convert the dependent variable `default` to a factor

```{r, comment = NA, warning = FALSE, message = FALSE}
library(tidyverse)
credit_data <- read_csv("https://raw.githubusercontent.com/obaidpervaizgill/CreditRiskModelling/master/credit.csv") %>% select(- 16) %>% 
  mutate(default = factor(default))
head(credit_data)

# Tabulating the dependent variable
table(credit_data$default)
```

#### Creating the train and test sets
We will use the `CreateDataPartition` function of the `caret` package to ensure proportionality of the response variable in the train and test sets.

```{r, comment = NA, warning = FALSE, message = FALSE}
library(caret)
indexes <- createDataPartition(credit_data$default, times = 1, p = 0.7)
train <- credit_data[indexes$Resample1, ]
test <- credit_data[-indexes$Resample1, ]

```

#### Training the model
We can use logistics regression since the response variable is binary.  

```{r, comment = NA, warning = FALSE, message = FALSE}
library(randomForest)
train_model <- randomForest(default ~., data = train)

# Predicting
test_pred <- predict(train_model, test[, 1:15])

```

#### Evaluating the model performance
```{r, comment = NA, warning = FALSE, message = FALSE}
actual_test <- credit_data[-indexes$Resample1, "default"]
actual_test <- as.factor(actual_test$default)

confusionMatrix(test_pred, actual_test)

```

Our model is upto 74% accurate in predicting loan defaulting. To improve the model performance, we would need to peforme feature engineering. 